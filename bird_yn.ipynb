{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjalipatel101/481_Project_Fall_2023/blob/bird_yn/bird_yn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWsmm7O3KI4Z"
      },
      "source": [
        "INITIAL SET UP (ALL BASES COVERED)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n__9FGO1VRan"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras.applications import imagenet_utils\n",
        "import numpy as np\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynVWkhCy0US1"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAasvW7j1vtj"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od\n",
        "import pandas\n",
        "\n",
        "od.download(\n",
        "    \"https://www.kaggle.com/datasets/rafsunahmad/choose-your-pet/\"\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49ftO_ZhJdrD"
      },
      "source": [
        "START HERE:\n",
        "Run each time and look through single and multi image display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8vuSQMSRlQ9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "#used for unmounting the drive\n",
        "#drive.flush_and_unmount()\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Unzip archive.zip for access to animal images\n",
        "!unzip '/content/drive/MyDrive/archive.zip'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWKhbhAQ0zOC",
        "outputId": "2e23fb18-75bb-4c7d-c8f5-5d72f24d350b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "icyGgx1MyOba"
      },
      "outputs": [],
      "source": [
        "#DISPLAYING SINGLE IMAGES TEST\n",
        "\n",
        "from IPython.display import display, Image\n",
        "from PIL import Image as PILImage\n",
        "\n",
        "# Set the path to your dataset in Google Drive\n",
        "dataset_path = '/content/Choose pet datset for kaggle/Cockatiel'\n",
        "\n",
        "# List files in the dataset directory\n",
        "file_list = os.listdir(dataset_path)\n",
        "first_image_path = os.path.join(dataset_path, file_list[10])\n",
        "img = PILImage.open(first_image_path)\n",
        "display(img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8RTyQyw42bzg"
      },
      "outputs": [],
      "source": [
        "#### DISPLAYING IMAGES TEST ####\n",
        "from IPython.display import display, Image\n",
        "from PIL import Image as PILImage\n",
        "import os\n",
        "\n",
        "# Set the path to your dataset in Google Drive\n",
        "dataset_path = '/content/Choose pet datset for kaggle/Cockatiel'\n",
        "\n",
        "# List files in the dataset directory\n",
        "file_list = os.listdir(dataset_path)\n",
        "\n",
        "# Iterate through all images and display each one\n",
        "for filename in file_list:\n",
        "    if filename.endswith(('.jpg', '.jpeg', '.png')):  # Filter only image files\n",
        "        image_path = os.path.join(dataset_path, filename)\n",
        "        img = PILImage.open(image_path)\n",
        "        display(img)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SzTBmU1KCdu"
      },
      "source": [
        "NEED TO FIX\n",
        "\n",
        "\n",
        "** Goal: train the data on the images to get it to output y/n if a picture is a bird or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "L1WtoaOHVrVh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "H74l2DoDI2XD"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/Choose pet datset for kaggle'"
      ],
      "metadata": {
        "id": "uCvzyP3DCL6J"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "fIR0kRZiI_AT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ddd254-5e1a-4f84-db3b-e252997db39c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2262 files belonging to 74 classes.\n",
            "Using 1810 files for training.\n"
          ]
        }
      ],
      "source": [
        "#This determines what images within the dataset will be used for training the model\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "iscU3UoVJBXj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb55985c-9466-499e-9100-5a1aa1434c3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2262 files belonging to 74 classes.\n",
            "Using 452 files for validation.\n"
          ]
        }
      ],
      "source": [
        "#This determines what images within the dataset will be used for validating the model\n",
        "\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing Purposes:\n",
        "class_names = train_ds.class_names\n",
        "print('Training: ', class_names)\n",
        "\n",
        "#Realized this was not going to work as images for training and testing were taken from all folders within the datsset\n",
        "#Thus, when outputting class names, it showed that the images for each respective set were from ALL the folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7YHk_PGDcg8",
        "outputId": "f8df5856-ab8f-402f-a172-f20fe0aa1bb2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training:  ['Abyssinian', 'African Dwarf Frog', 'African Grey Parrot', 'American Shorthair', 'American Toad', 'Axolotls', 'Beagle', 'Bearded Dragon', 'Bengal', \"Bourke's Parakeet\", 'Boxer', 'British Shorthair', 'Budgerigar', 'Bulldog', 'Burmese', 'Canary', 'Chameleon', 'Chinchillas', 'Cockatiel', 'Cockatoo', 'Cocker Spaniel', 'Crested Gecko', 'Dachshund', 'Degus', 'Devon Rex', 'Eastern Newt', 'Egyptian Mau', 'Ferrets', 'Finch', 'Fox', 'French Bulldog', 'Frogs with Tadpoles', 'Gerbils', 'German Shepherd', 'Golden Retriever', 'Great Dane', 'Green Iguana', 'Guinea Pigs', 'Hamsters', 'Hedgehogs', 'Himalayan', 'Horned Toads', 'Horses', 'Hyacinth Macaws', 'Labrador Retriever', 'Leopard Gecko', 'Lovebird', 'Maine Coon', 'Mice', 'Miniature Schnauzer', 'Monitor Lizards', 'Parrotlet', 'Persian', 'Pionus Parrot', 'Poison Dart Frogs', 'Poodle', 'Prairie Dogs', 'Quaker Parrot', 'Rabbits', 'Ragdoll', 'Rats', 'Red-eyed Tree Frog', 'Rottweiler', 'Russian Blue', 'Salamander', 'Scottish Fold', 'Serval Cats', 'Shih Tzu', 'Siamese', 'Sphynx', 'Sugar Gliders', 'Wallabies', \"White's Tree Frog\", 'Yorkshire Terrier']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "wBmEA9c0JYes",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "fb839e90-8c29-4143-fd29-ff48a236788f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-d17c8cbbcb34>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    807\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    773\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3026\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3028\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3029\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3030\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5886\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5887\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5888\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required.\n\t [[{{node decode_image/DecodeImage}}]] [Op:IteratorGetNext] name: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81FudAW3OvDX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions\n",
        "\n",
        "# Load the pre-trained MobileNetV2 model\n",
        "model = MobileNetV2(weights='imagenet')\n",
        "\n",
        "def predict_bird(image_path):\n",
        "    # Load and preprocess the input image\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = img_array / 255.0  # Normalize pixel values to be between 0 and 1\n",
        "    img_array = preprocess_input(np.expand_dims(img_array, axis=0))\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(img_array)\n",
        "    decoded_predictions = decode_predictions(predictions, top=1)[0]\n",
        "\n",
        "    # Check if the top prediction is a bird\n",
        "    return \"bird\" in decoded_predictions[0][1].lower()\n",
        "\n",
        "def identify_birds_in_dataset(dataset_dir):\n",
        "    # Iterate through each file in the directory\n",
        "    for filename in os.listdir(dataset_dir):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "            # Construct the full path to the image\n",
        "            image_path = os.path.join(dataset_dir, filename)\n",
        "\n",
        "            # Use the predict_bird function to determine if the image contains a bird\n",
        "            is_bird = predict_bird(image_path)\n",
        "\n",
        "            # Print the result\n",
        "            if is_bird:\n",
        "                print(f\"{filename}: The animal in the image is a bird.\")\n",
        "            else:\n",
        "                print(f\"{filename}: The animal in the image is not a bird.\")\n",
        "\n",
        "# Directory containing the animal dataset\n",
        "animal_dataset_dir = '/content/Choose pet datset for kaggle/Canary'\n",
        "\n",
        "# Identify birds in the dataset\n",
        "identify_birds_in_dataset(animal_dataset_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9kcHgFTlDeKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66nBnw-lwXfZ"
      },
      "outputs": [],
      "source": [
        "#mobile = keras.applications.mobilenet.MobileNet()\n",
        "\n",
        "#def img_prep(file):\n",
        " # img_path = ' '\n",
        "  #img = image.load_img(img_path + file, target_size=(224,224))\n",
        "  #biarray = image.img_to_array(img)\n",
        "  #biarray_large = np.expand_dims(img_array, axis = 0)\n",
        "  #return keras.applications.mobilenet.preprocess_input(biarray_large)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1xYggZB-e88t6DRiCW6aUnnSjhlUHKoHL",
      "authorship_tag": "ABX9TyMpTNrYSxyRwUmplFZ8amDt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}